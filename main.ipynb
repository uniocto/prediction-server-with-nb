{
    "cells": [
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "# init"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "import json\n",
       "import pickle\n",
       "import numpy as np\n",
       "from datetime import datetime\n",
       "from wsgiref.util import setup_testing_defaults\n",
       "from wsgiref.simple_server import make_server"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "PORT = 8000"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "class ModelPredictor:\n",
       "    \"\"\"this class is body persing and predict.\n",
       "\n",
       "    attributes:\n",
       "        model(:obj:): model.\n",
       "\n",
       "    \"\"\"\n",
       "    \n",
       "    def __init__(self):\n",
       "        \"\"\"init predictor\n",
       "\n",
       "        load model\n",
       "\n",
       "        \"\"\"\n",
       "        self.model = pickle.load(open('model', 'rb'))\n",
       "\n",
       "\n",
       "    def main(self,data):\n",
       "        \"\"\"main function\n",
       "    \n",
       "        Args:\n",
       "           obj(object:dict): dict object.\n",
       "    \n",
       "        Returns:\n",
       "            byte object\n",
       "\n",
       "        Examples:\n",
       "            >>> ModelPredictor().main({\"sepal length (cm)\":1,\"sepal width (cm)\":2,\"petal length (cm)\":3,\"petal width (cm)\":4})\n",
       "            b{\"val\": 2}\n",
       "        \"\"\"\n",
       "        return json.dumps({\"val\": self.predict(self.prep(data))} ,cls = NumpyEncoder).encode()\n",
       "    \n",
       "\n",
       "    def prep(self,data):\n",
       "        \"\"\"preparate requested data\n",
       "    \n",
       "        Args:\n",
       "           data (object:dict): dict object.\n",
       "    \n",
       "        Returns:\n",
       "            2 dimension list\n",
       "\n",
       "        Examples:\n",
       "            >>> ModelPredictor().prep({\"sepal length (cm)\":1,\"sepal width (cm)\":2,\"petal length (cm)\":3,\"petal width (cm)\":4})\n",
       "            [[1,2,3,4]]\n",
       "        \"\"\"\n",
       "        return [[   data['sepal length (cm)'],\n",
       "                    data['sepal width (cm)'],\n",
       "                    data['petal length (cm)'],\n",
       "                    data['petal width (cm)']]]\n",
       "\n",
       "\n",
       "    def predict(self,data):\n",
       "        \"\"\"predict from recieve data\n",
       "    \n",
       "        predict from recieve data\n",
       "    \n",
       "        Args:\n",
       "           recieve(obj:): http recieved object\n",
       "    \n",
       "        Returns:\n",
       "            bytes: byte object\n",
       "\n",
       "        Examples:\n",
       "            >>> ModelPredictor().predict([[1,2,3,4]])\n",
       "            2\n",
       "        \"\"\"\n",
       "        return self.model.predict(data)[0]"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "class NumpyEncoder(json.JSONEncoder):\n",
       "    \"\"\"numpy data encode\n",
       "\n",
       "    attributes:\n",
       "        model(:obj:): model.\n",
       "\n",
       "    \"\"\"\n",
       "\n",
       "\n",
       "    def default(self, obj):\n",
       "        \"\"\"validate object\n",
       "    \n",
       "        Args:\n",
       "           obj(np.object): numpy object.\n",
       "    \n",
       "        Returns:\n",
       "            (obj: int | float | list): object\n",
       "\n",
       "        \"\"\"\n",
       "        if isinstance(obj, np.integer):\n",
       "            return int(obj)\n",
       "        elif isinstance(obj, np.floating):\n",
       "            return float(obj)\n",
       "        elif isinstance(obj, np.ndarray):\n",
       "            return obj.tolist()\n",
       "        else:\n",
       "            return super(NumpyEncoder, self).default(obj)"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "prd_controller = ModelPredictor()"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "# create prediction server"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
       "inputHidden": false,
       "outputHidden": false
      },
      "outputs": [],
      "source": [
       "def simple_app(environ, start_response):\n",
       "    \"\"\"\n",
       "    \n",
       "    Args:\n",
       "        obj(np.object): numpy object.\n",
       "\n",
       "    Returns:\n",
       "        (obj: int | float | list): object\n",
       "    \n",
       "    \"\"\"\n",
       "    setup_testing_defaults(environ)\n",
       "    \n",
       "    wsgi_input = environ[\"wsgi.input\"]\n",
       "    content_length = int(environ[\"CONTENT_LENGTH\"])\n",
       "    data = json.loads(wsgi_input.read(content_length))\n",
       "    print(wsgi_input)\n",
       "    print(data)\n",
       "    status = '200 OK'\n",
       "    headers = [('Content-type', 'text/plain; charset=utf-8')]\n",
       "    ret = [prd_controller.main(data)]\n",
       "    start_response(status, headers)\n",
       "\n",
       "    return ret"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "with make_server('0.0.0.0', PORT, simple_app) as httpd:\n",
       "    print(\"Serving on port ${PORT}...\")\n",
       "    httpd.serve_forever()"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
     }
    ],
    "metadata": {
     "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
     },
     "language_info": {
      "codemirror_mode": {
       "name": "ipython",
       "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
     },
     "nteract": {
      "version": "nteract-on-jupyter@2.1.3"
     }
    },
    "nbformat": 4,
    "nbformat_minor": 4
   }